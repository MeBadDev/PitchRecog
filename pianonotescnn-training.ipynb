{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684d7ace",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-05T15:23:59.204625Z",
     "iopub.status.busy": "2025-04-05T15:23:59.204231Z",
     "iopub.status.idle": "2025-04-05T15:24:44.112101Z",
     "shell.execute_reply": "2025-04-05T15:24:44.111053Z"
    },
    "papermill": {
     "duration": 44.91449,
     "end_time": "2025-04-05T15:24:44.115021",
     "exception": false,
     "start_time": "2025-04-05T15:23:59.200531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully unzipped '/kaggle/input/pianonotescnn-preprocessing/_output_.zip' to '/kaggle/temp'\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def unzip_file(zip_file_path, extract_to_path):\n",
    "    \"\"\"Unzips a zip file to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        zip_file_path (str): The path to the zip file.\n",
    "        extract_to_path (str): The path to the directory where the contents will be extracted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to_path)\n",
    "        print(f\"Successfully unzipped '{zip_file_path}' to '{extract_to_path}'\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The zip file '{zip_file_path}' was not found.\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: '{zip_file_path}' is not a valid zip file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during unzipping: {e}\")\n",
    "\n",
    "\n",
    "zip_file = \"/kaggle/input/pianonotescnn-preprocessing/_output_.zip\"\n",
    "extract_dir = \"/kaggle/temp\"\n",
    "unzip_file(zip_file, extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327f04df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:24:44.120833Z",
     "iopub.status.busy": "2025-04-05T15:24:44.120443Z",
     "iopub.status.idle": "2025-04-05T15:24:44.127607Z",
     "shell.execute_reply": "2025-04-05T15:24:44.126705Z"
    },
    "papermill": {
     "duration": 0.011669,
     "end_time": "2025-04-05T15:24:44.129105",
     "exception": false,
     "start_time": "2025-04-05T15:24:44.117436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed file: /kaggle/working/__notebook__.ipynb\n",
      "Successfully cleared the contents of: /kaggle/working/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def clear_working_directory(directory=\"/kaggle/working/\"):\n",
    "    \"\"\"Removes all files and directories within the specified directory.\"\"\"\n",
    "    try:\n",
    "        for item in os.listdir(directory):\n",
    "            item_path = os.path.join(directory, item)\n",
    "            if os.path.isfile(item_path):\n",
    "                os.remove(item_path)\n",
    "                print(f\"Removed file: {item_path}\")\n",
    "            elif os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)\n",
    "                print(f\"Removed directory: {item_path}\")\n",
    "        print(f\"Successfully cleared the contents of: {directory}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Directory not found: {directory}\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: Could not clear directory {directory}. {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# clear_working_directory()\n",
    "\n",
    "clear_working_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e8fcd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:24:44.134710Z",
     "iopub.status.busy": "2025-04-05T15:24:44.134370Z",
     "iopub.status.idle": "2025-04-05T15:24:52.777012Z",
     "shell.execute_reply": "2025-04-05T15:24:52.775662Z"
    },
    "papermill": {
     "duration": 8.64723,
     "end_time": "2025-04-05T15:24:52.778791",
     "exception": false,
     "start_time": "2025-04-05T15:24:44.131561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretty_midi\r\n",
      "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.26.4)\r\n",
      "Collecting mido>=1.1.16 (from pretty_midi)\r\n",
      "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.17.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mido>=1.1.16->pretty_midi) (24.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7.0->pretty_midi) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7.0->pretty_midi) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7.0->pretty_midi) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7.0->pretty_midi) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7.0->pretty_midi) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7.0->pretty_midi) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.7.0->pretty_midi) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.7.0->pretty_midi) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.7.0->pretty_midi) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.7.0->pretty_midi) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.7.0->pretty_midi) (2024.2.0)\r\n",
      "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pretty_midi\r\n",
      "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592287 sha256=704311086728804d84fd5d56361c4fc33d098988c48bd78125d2507af99f89f8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\r\n",
      "Successfully built pretty_midi\r\n",
      "Installing collected packages: mido, pretty_midi\r\n",
      "Successfully installed mido-1.3.3 pretty_midi-0.2.10\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pretty_midi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae0e4e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:24:52.786569Z",
     "iopub.status.busy": "2025-04-05T15:24:52.786221Z",
     "iopub.status.idle": "2025-04-05T15:47:29.743898Z",
     "shell.execute_reply": "2025-04-05T15:47:29.742868Z"
    },
    "papermill": {
     "duration": 1357.658843,
     "end_time": "2025-04-05T15:47:30.440883",
     "exception": false,
     "start_time": "2025-04-05T15:24:52.782040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculated Class Weights (Positive Class): [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "Loading data into memory...\n",
      "Converting to TensorFlow tensors...\n",
      "Data loaded onto GPU.\n",
      "\n",
      "Loading data splits...\n",
      "Found 120000 training samples.\n",
      "Found 15000 validation samples.\n",
      "Found 15000 test samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"PianoNoteCNN_GRU\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"PianoNoteCNN_GRU\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,344</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,616</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ permute (\u001b[38;5;33mPermute\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m393,344\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m99,072\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m)                  │          \u001b[38;5;34m22,616\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">939,352</span> (3.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m939,352\u001b[0m (3.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">937,624</span> (3.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m937,624\u001b[0m (3.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> (6.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,728\u001b[0m (6.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch 1/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - auc: 0.5172 - loss: 1.2829 - precision: 0.0367 - recall: 0.3564 - val_auc: 0.7472 - val_loss: 0.5673 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - auc: 0.7290 - loss: 0.4931 - precision: 0.1560 - recall: 0.0011 - val_auc: 0.7907 - val_loss: 0.3487 - val_precision: 0.8367 - val_recall: 9.1518e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.7901 - loss: 0.3347 - precision: 0.3259 - recall: 0.0289 - val_auc: 0.8460 - val_loss: 0.2781 - val_precision: 0.6821 - val_recall: 0.1031\n",
      "Epoch 4/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.8352 - loss: 0.2816 - precision: 0.4544 - recall: 0.1467 - val_auc: 0.8867 - val_loss: 0.2424 - val_precision: 0.6023 - val_recall: 0.2485\n",
      "Epoch 5/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.8667 - loss: 0.2546 - precision: 0.4763 - recall: 0.2457 - val_auc: 0.9058 - val_loss: 0.2241 - val_precision: 0.5868 - val_recall: 0.3161\n",
      "Epoch 6/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - auc: 0.8820 - loss: 0.2412 - precision: 0.4774 - recall: 0.2986 - val_auc: 0.9180 - val_loss: 0.2122 - val_precision: 0.6013 - val_recall: 0.3565\n",
      "Epoch 7/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - auc: 0.8913 - loss: 0.2333 - precision: 0.4818 - recall: 0.3309 - val_auc: 0.9173 - val_loss: 0.2107 - val_precision: 0.6019 - val_recall: 0.3528\n",
      "Epoch 8/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.8982 - loss: 0.2275 - precision: 0.4820 - recall: 0.3567 - val_auc: 0.9247 - val_loss: 0.2076 - val_precision: 0.5712 - val_recall: 0.3997\n",
      "Epoch 9/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9032 - loss: 0.2224 - precision: 0.4841 - recall: 0.3725 - val_auc: 0.9309 - val_loss: 0.1981 - val_precision: 0.6260 - val_recall: 0.3925\n",
      "Epoch 10/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - auc: 0.9064 - loss: 0.2200 - precision: 0.4853 - recall: 0.3854 - val_auc: 0.9311 - val_loss: 0.1977 - val_precision: 0.5967 - val_recall: 0.4254\n",
      "Epoch 11/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9093 - loss: 0.2169 - precision: 0.4855 - recall: 0.3955 - val_auc: 0.9331 - val_loss: 0.1956 - val_precision: 0.5830 - val_recall: 0.4411\n",
      "Epoch 12/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9110 - loss: 0.2157 - precision: 0.4874 - recall: 0.4066 - val_auc: 0.9360 - val_loss: 0.1895 - val_precision: 0.5901 - val_recall: 0.4590\n",
      "Epoch 13/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9129 - loss: 0.2136 - precision: 0.4854 - recall: 0.4110 - val_auc: 0.9395 - val_loss: 0.1854 - val_precision: 0.6091 - val_recall: 0.4561\n",
      "Epoch 14/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9144 - loss: 0.2122 - precision: 0.4898 - recall: 0.4197 - val_auc: 0.9404 - val_loss: 0.1842 - val_precision: 0.5688 - val_recall: 0.4968\n",
      "Epoch 15/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9155 - loss: 0.2115 - precision: 0.4885 - recall: 0.4236 - val_auc: 0.9409 - val_loss: 0.1849 - val_precision: 0.5798 - val_recall: 0.4889\n",
      "Epoch 16/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9161 - loss: 0.2104 - precision: 0.4906 - recall: 0.4265 - val_auc: 0.9431 - val_loss: 0.1828 - val_precision: 0.5902 - val_recall: 0.4911\n",
      "Epoch 17/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9179 - loss: 0.2088 - precision: 0.4914 - recall: 0.4320 - val_auc: 0.9418 - val_loss: 0.1824 - val_precision: 0.5863 - val_recall: 0.4913\n",
      "Epoch 18/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9176 - loss: 0.2090 - precision: 0.4900 - recall: 0.4347 - val_auc: 0.9436 - val_loss: 0.1825 - val_precision: 0.6009 - val_recall: 0.4852\n",
      "Epoch 19/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9181 - loss: 0.2086 - precision: 0.4907 - recall: 0.4354 - val_auc: 0.9443 - val_loss: 0.1792 - val_precision: 0.5887 - val_recall: 0.5082\n",
      "Epoch 20/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9191 - loss: 0.2079 - precision: 0.4925 - recall: 0.4397 - val_auc: 0.9444 - val_loss: 0.1801 - val_precision: 0.6012 - val_recall: 0.4956\n",
      "Epoch 21/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - auc: 0.9200 - loss: 0.2067 - precision: 0.4934 - recall: 0.4425 - val_auc: 0.9414 - val_loss: 0.1835 - val_precision: 0.5806 - val_recall: 0.5010\n",
      "Epoch 22/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - auc: 0.9193 - loss: 0.2075 - precision: 0.4927 - recall: 0.4418 - val_auc: 0.9450 - val_loss: 0.1819 - val_precision: 0.5750 - val_recall: 0.5155\n",
      "Epoch 23/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9209 - loss: 0.2056 - precision: 0.4947 - recall: 0.4469 - val_auc: 0.9424 - val_loss: 0.1820 - val_precision: 0.5742 - val_recall: 0.5062\n",
      "Epoch 24/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9211 - loss: 0.2057 - precision: 0.4954 - recall: 0.4485 - val_auc: 0.9449 - val_loss: 0.1796 - val_precision: 0.5876 - val_recall: 0.5091\n",
      "Epoch 25/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9217 - loss: 0.2053 - precision: 0.4969 - recall: 0.4508 - val_auc: 0.9443 - val_loss: 0.1821 - val_precision: 0.5598 - val_recall: 0.5352\n",
      "Epoch 26/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9226 - loss: 0.2045 - precision: 0.4972 - recall: 0.4547 - val_auc: 0.9424 - val_loss: 0.1824 - val_precision: 0.5983 - val_recall: 0.4873\n",
      "Epoch 27/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9216 - loss: 0.2055 - precision: 0.4954 - recall: 0.4516 - val_auc: 0.9455 - val_loss: 0.1774 - val_precision: 0.5992 - val_recall: 0.5086\n",
      "Epoch 28/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9227 - loss: 0.2045 - precision: 0.4953 - recall: 0.4543 - val_auc: 0.9441 - val_loss: 0.1802 - val_precision: 0.5774 - val_recall: 0.5201\n",
      "Epoch 29/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9230 - loss: 0.2040 - precision: 0.4958 - recall: 0.4568 - val_auc: 0.9423 - val_loss: 0.1831 - val_precision: 0.6166 - val_recall: 0.4701\n",
      "Epoch 30/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9237 - loss: 0.2034 - precision: 0.4967 - recall: 0.4602 - val_auc: 0.9467 - val_loss: 0.1770 - val_precision: 0.6071 - val_recall: 0.5029\n",
      "Epoch 31/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9231 - loss: 0.2039 - precision: 0.4977 - recall: 0.4584 - val_auc: 0.9462 - val_loss: 0.1773 - val_precision: 0.5933 - val_recall: 0.5152\n",
      "Epoch 32/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9241 - loss: 0.2028 - precision: 0.5002 - recall: 0.4622 - val_auc: 0.9443 - val_loss: 0.1792 - val_precision: 0.5885 - val_recall: 0.5075\n",
      "Epoch 33/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9243 - loss: 0.2029 - precision: 0.4992 - recall: 0.4615 - val_auc: 0.9406 - val_loss: 0.1846 - val_precision: 0.5787 - val_recall: 0.5019\n",
      "Epoch 34/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9253 - loss: 0.2017 - precision: 0.5007 - recall: 0.4684 - val_auc: 0.9468 - val_loss: 0.1782 - val_precision: 0.6145 - val_recall: 0.4936\n",
      "Epoch 35/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9251 - loss: 0.2018 - precision: 0.5005 - recall: 0.4652 - val_auc: 0.9462 - val_loss: 0.1769 - val_precision: 0.5900 - val_recall: 0.5197\n",
      "Epoch 36/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9254 - loss: 0.2016 - precision: 0.5001 - recall: 0.4671 - val_auc: 0.9349 - val_loss: 0.1907 - val_precision: 0.5738 - val_recall: 0.4833\n",
      "Epoch 37/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9255 - loss: 0.2010 - precision: 0.4995 - recall: 0.4680 - val_auc: 0.9451 - val_loss: 0.1782 - val_precision: 0.5889 - val_recall: 0.5098\n",
      "Epoch 38/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9261 - loss: 0.2010 - precision: 0.5009 - recall: 0.4702 - val_auc: 0.9484 - val_loss: 0.1742 - val_precision: 0.5895 - val_recall: 0.5345\n",
      "Epoch 39/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9256 - loss: 0.2010 - precision: 0.5004 - recall: 0.4696 - val_auc: 0.9442 - val_loss: 0.1787 - val_precision: 0.5842 - val_recall: 0.5180\n",
      "Epoch 40/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9260 - loss: 0.2011 - precision: 0.5001 - recall: 0.4711 - val_auc: 0.9450 - val_loss: 0.1794 - val_precision: 0.5949 - val_recall: 0.5159\n",
      "Epoch 41/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9264 - loss: 0.2009 - precision: 0.5019 - recall: 0.4732 - val_auc: 0.9494 - val_loss: 0.1730 - val_precision: 0.5899 - val_recall: 0.5363\n",
      "Epoch 42/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9263 - loss: 0.2005 - precision: 0.5014 - recall: 0.4727 - val_auc: 0.9490 - val_loss: 0.1734 - val_precision: 0.5812 - val_recall: 0.5426\n",
      "Epoch 43/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9268 - loss: 0.2000 - precision: 0.5017 - recall: 0.4748 - val_auc: 0.9478 - val_loss: 0.1752 - val_precision: 0.5897 - val_recall: 0.5319\n",
      "Epoch 44/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9272 - loss: 0.1994 - precision: 0.5034 - recall: 0.4779 - val_auc: 0.9480 - val_loss: 0.1744 - val_precision: 0.6092 - val_recall: 0.5223\n",
      "Epoch 45/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9272 - loss: 0.1996 - precision: 0.5057 - recall: 0.4761 - val_auc: 0.9475 - val_loss: 0.1754 - val_precision: 0.6047 - val_recall: 0.5128\n",
      "Epoch 46/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9268 - loss: 0.2002 - precision: 0.5034 - recall: 0.4768 - val_auc: 0.9403 - val_loss: 0.1845 - val_precision: 0.5588 - val_recall: 0.5297\n",
      "Epoch 47/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9267 - loss: 0.2004 - precision: 0.5031 - recall: 0.4751 - val_auc: 0.9428 - val_loss: 0.1820 - val_precision: 0.5911 - val_recall: 0.4992\n",
      "Epoch 48/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9273 - loss: 0.1998 - precision: 0.5027 - recall: 0.4779 - val_auc: 0.9401 - val_loss: 0.1854 - val_precision: 0.5848 - val_recall: 0.4961\n",
      "Epoch 49/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9272 - loss: 0.1999 - precision: 0.5049 - recall: 0.4776 - val_auc: 0.9495 - val_loss: 0.1722 - val_precision: 0.5892 - val_recall: 0.5441\n",
      "Epoch 50/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9273 - loss: 0.2002 - precision: 0.5028 - recall: 0.4773 - val_auc: 0.9509 - val_loss: 0.1711 - val_precision: 0.6020 - val_recall: 0.5398\n",
      "Epoch 51/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9284 - loss: 0.1984 - precision: 0.5053 - recall: 0.4827 - val_auc: 0.9432 - val_loss: 0.1797 - val_precision: 0.5621 - val_recall: 0.5410\n",
      "Epoch 52/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9283 - loss: 0.1987 - precision: 0.5072 - recall: 0.4823 - val_auc: 0.9466 - val_loss: 0.1752 - val_precision: 0.5925 - val_recall: 0.5261\n",
      "Epoch 53/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9283 - loss: 0.1987 - precision: 0.5057 - recall: 0.4822 - val_auc: 0.9366 - val_loss: 0.1886 - val_precision: 0.5573 - val_recall: 0.5127\n",
      "Epoch 54/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9283 - loss: 0.1982 - precision: 0.5055 - recall: 0.4825 - val_auc: 0.9463 - val_loss: 0.1768 - val_precision: 0.5631 - val_recall: 0.5512\n",
      "Epoch 55/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9284 - loss: 0.1985 - precision: 0.5059 - recall: 0.4844 - val_auc: 0.9479 - val_loss: 0.1754 - val_precision: 0.6059 - val_recall: 0.5198\n",
      "Epoch 56/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9287 - loss: 0.1983 - precision: 0.5064 - recall: 0.4860 - val_auc: 0.9491 - val_loss: 0.1750 - val_precision: 0.5905 - val_recall: 0.5383\n",
      "Epoch 57/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9291 - loss: 0.1979 - precision: 0.5079 - recall: 0.4855 - val_auc: 0.9470 - val_loss: 0.1768 - val_precision: 0.5899 - val_recall: 0.5335\n",
      "Epoch 58/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9290 - loss: 0.1981 - precision: 0.5079 - recall: 0.4868 - val_auc: 0.9465 - val_loss: 0.1767 - val_precision: 0.5889 - val_recall: 0.5296\n",
      "Epoch 59/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9292 - loss: 0.1978 - precision: 0.5074 - recall: 0.4873 - val_auc: 0.9380 - val_loss: 0.1865 - val_precision: 0.5538 - val_recall: 0.5281\n",
      "Epoch 60/100\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - auc: 0.9296 - loss: 0.1975 - precision: 0.5064 - recall: 0.4892 - val_auc: 0.9450 - val_loss: 0.1770 - val_precision: 0.5587 - val_recall: 0.5572\n",
      "\n",
      "Training finished.\n",
      "\n",
      "Evaluating on test set...\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.9500 - loss: 0.1735 - precision: 0.6100 - recall: 0.5361\n",
      "\n",
      "Test Loss: 0.17289632558822632\n",
      "Test Precision: 0.6070417165756226\n",
      "Test Recall: 0.537784218788147\n",
      "Test AUC: 0.95013827085495\n",
      "\n",
      "Best model saved to /kaggle/working/best.keras\n",
      "Final model saved to /kaggle/working/final.keras\n"
     ]
    }
   ],
   "source": [
    "# # MAESTRO Model Training Script\n",
    "#\n",
    "# This script trains a model for piano note recognition using the\n",
    "# preprocessed data from the MAESTRO dataset.\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Import mixed precision module\n",
    "from keras import layers, models, mixed_precision\n",
    "import json\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pretty_midi # Ensure this is installed if running locally\n",
    "\n",
    "# ## 1. Configuration\n",
    "\n",
    "# Path to the processed data directory (must match your preprocessing script)\n",
    "PROCESSED_DATA_PATH = \"/kaggle/temp/random_frames\"\n",
    "# Load dataset info to get parameters used during preprocessing\n",
    "# DATASET_INFO_PATH = os.path.join(PROCESSED_DATA_PATH, 'dataset_info.json') # dataset_info.json is not created in random sampling\n",
    "\n",
    "# Model & Training Parameters\n",
    "# Input shape depends on the mel spectrogram dimensions from preprocessing\n",
    "# (n_mels, time_steps_in_mel_spectrogram)\n",
    "# Let's load one sample to determine the shape\n",
    "# Adjust BATCH_SIZE and EPOCHS based on your system resources and desired training time\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100# Start with a small number and increase as needed\n",
    "N_KEYS = 88  # Number of piano keys (output size)\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 0.1 # You mentioned changing this\n",
    "HOP_LENGTH = 512\n",
    "N_FFT = 512 # You mentioned changing this\n",
    "N_MELS = 64 # You mentioned changing this\n",
    "FMIN = 27.5\n",
    "FMAX = 4186.0\n",
    "TOTAL_FRAMES_TO_SAVE = 150000\n",
    "\n",
    "# ## Data Loading Block (Added by User)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to your processed data\n",
    "PROCESSED_DATA_PATH = \"/kaggle/temp/random_frames\"\n",
    "FEATURES_DIR = os.path.join(PROCESSED_DATA_PATH, 'features')\n",
    "LABELS_DIR = os.path.join(PROCESSED_DATA_PATH, 'labels')\n",
    "\n",
    "\n",
    "\n",
    "def calculate_class_weights(note_counts, max_weight=10.0): # Keeping the max_weight parameter for consistency, though it won't be used here\n",
    "    \"\"\"\n",
    "    Returns a constant weight of 3 for the positive class of each note.\n",
    "    The note_counts and max_weight parameters are kept for consistency with the original function signature\n",
    "    but are not used in this implementation.\n",
    "    \"\"\"\n",
    "    class_weights = np.full(88, 3.0, dtype=np.float32) # Create an array of 88 elements, all set to 3.0\n",
    "    return class_weights\n",
    "\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = calculate_class_weights(0, 3.0)\n",
    "print(\"\\nCalculated Class Weights (Positive Class):\", class_weights)\n",
    "\n",
    "# 1. Collect all feature and label file paths\n",
    "feature_files = sorted(glob.glob(os.path.join(FEATURES_DIR, '*.npz')))\n",
    "label_files = sorted(glob.glob(os.path.join(LABELS_DIR, '*.npy')))\n",
    "\n",
    "# 2. Load all data into lists (or NumPy arrays)\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"Loading data into memory...\")\n",
    "for feature_file, label_file in zip(feature_files, label_files):\n",
    "    with np.load(feature_file) as data:\n",
    "        all_features.append(data['mel_spectrogram'])\n",
    "    all_labels.append(np.load(label_file))\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "all_features_np = np.array(all_features, dtype=np.float32)\n",
    "all_labels_np = np.array(all_labels, dtype=np.float32).squeeze(axis=1) # Assuming you fixed the label shape\n",
    "\n",
    "# *** ADD THIS LINE HERE ***\n",
    "all_features_np = np.expand_dims(all_features_np, axis=-1) # Add a channel dimension at the end\n",
    "\n",
    "print(\"Converting to TensorFlow tensors...\")\n",
    "# 3. Convert NumPy arrays to TensorFlow tensors\n",
    "all_features_tensor = tf.convert_to_tensor(all_features_np)\n",
    "all_labels_tensor = tf.convert_to_tensor(all_labels_np)\n",
    "# 4. Move tensors to the GPU (if available)\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    with tf.device('/GPU:0'):  # Assuming you have one GPU\n",
    "        gpu_features = all_features_tensor\n",
    "        gpu_labels = all_labels_tensor\n",
    "        print(\"Data loaded onto GPU.\")\n",
    "else:\n",
    "    print(\"No GPU found, data remains on CPU.\")\n",
    "\n",
    "# ## 4. Define the Model Architecture (Simple CNN Example)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers # Make sure regularizers is imported if used directly\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Builds a corrected CNN-GRU model for piano note recognition.\n",
    "\n",
    "    Assumes input_shape is (N_MELS, time_steps, 1), where time_steps=4\n",
    "    based on the previous error diagnosis.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The shape of the input tensor (e.g., (64, 4, 1)).\n",
    "        num_classes (int): The number of output classes (e.g., 88 piano keys).\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The Keras model.\n",
    "    \"\"\"\n",
    "    # input_shape[0] = N_MELS (e.g., 64)\n",
    "    # input_shape[1] = time_steps (e.g., 4)\n",
    "    # input_shape[2] = channels (e.g., 1)\n",
    "    if input_shape[1] != 4:\n",
    "        print(f\"Warning: build_model expects input_shape with 4 time steps based on previous error,\"\n",
    "              f\" but received input_shape={input_shape}. Shapes might mismatch if data isn't (N_MELS, 4, 1).\")\n",
    "\n",
    "    model = models.Sequential(name=\"PianoNoteCNN_GRU\")\n",
    "    model.add(layers.Input(shape=input_shape)) # Expecting (None, 64, 4, 1)\n",
    "\n",
    "    # --- Convolutional Blocks ---\n",
    "    # Each MaxPooling2D(pool_size=(2, 1)) halves the first dimension (height/N_MELS)\n",
    "    # It leaves the second dimension (width/time_steps) unchanged.\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same',\n",
    "                             kernel_regularizer=regularizers.L2(0.0005)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 1))) # Shape: (None, 32, 4, 32)\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same',\n",
    "                             kernel_regularizer=regularizers.L2(0.0005)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 1))) # Shape: (None, 16, 4, 64)\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same',\n",
    "                             kernel_regularizer=regularizers.L2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 1))) # Shape: (None, 8, 4, 128)\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    # New Deeper Convolutional Block\n",
    "    model.add(layers.Conv2D(256, (3, 3), padding='same',\n",
    "                             kernel_regularizer=regularizers.L2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 1))) # Shape: (None, 4, 4, 256)\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    # --- Prepare for 1D Processing ---\n",
    "    # Transpose to put time dimension first after batch: (batch, time, features...)\n",
    "    # Input shape: (None, pooled_height, time_steps, channels) -> (None, 4, 4, 256)\n",
    "    # Target axes: (batch, time_steps, pooled_height, channels) -> (0, 2, 1, 3)\n",
    "    model.add(layers.Permute((2, 1, 3))) # Shape: (None, 4, 4, 256)\n",
    "\n",
    "    # Reshape to combine the pooled_height and channel dimensions into a single feature dimension\n",
    "    # Input shape: (None, 4, 4, 256) <- (batch, time_steps, pooled_height, channels)\n",
    "    # Target shape: (batch, time_steps, pooled_height * channels)\n",
    "    pooled_height_dim = input_shape[0] // (2**4) # 64 / 16 = 4\n",
    "    last_conv_filters = 256\n",
    "    num_features_for_1d = pooled_height_dim * last_conv_filters # 4 * 256 = 1024\n",
    "\n",
    "    # target_shape should be (time_steps, num_features_for_1d)\n",
    "    # input_shape[1] is the original time_steps dimension (which is 4)\n",
    "    model.add(layers.Reshape(target_shape=(input_shape[1], num_features_for_1d))) # Target: (4, 1024), Output shape: (None, 4, 1024)\n",
    "\n",
    "    # --- 1D Convolution and Recurrent Layers ---\n",
    "    # Process the sequence along the time dimension (4 steps)\n",
    "    # Input shape: (None, 4, 1024)\n",
    "    model.add(layers.Conv1D(128, 3, padding='same', # Kernel size 3 on 4 steps is okay\n",
    "                             kernel_regularizer=regularizers.L2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2)) # Reduces time dimension: Output shape (None, 2, 128)\n",
    "\n",
    "    # GRU Layer processes the sequence output by Conv1D/Pool1D\n",
    "    # Input shape: (None, 2, 128)\n",
    "    model.add(layers.GRU(128)) # Output shape (None, 128) - GRU outputs the final state by default\n",
    "\n",
    "    # --- Dense Layers for Classification ---\n",
    "    model.add(layers.Dense(256, activation='relu',\n",
    "                             kernel_regularizer=regularizers.L2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='sigmoid', dtype='float32')) # Sigmoid for multi-label classification\n",
    "\n",
    "    return model\n",
    "\n",
    "# ## 5. Define Custom Weighted Loss Function\n",
    "\n",
    "def weighted_binary_crossentropy(pos_weights):\n",
    "    \"\"\"\n",
    "    pos_weights: a NumPy array of shape (num_classes,) representing\n",
    "                 the weight for each class when the true label is 1.\n",
    "    Returns a loss function that applies weighted binary crossentropy.\n",
    "    \"\"\"\n",
    "    pos_weights = tf.constant(pos_weights, dtype=tf.float32)\n",
    "    def loss(y_true, y_pred):\n",
    "        # Compute standard binary crossentropy for each element\n",
    "        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        # Weight positive labels using pos_weights; negatives remain 1\n",
    "        weight_matrix = y_true * pos_weights + (1 - y_true)\n",
    "        weighted_bce = bce * weight_matrix\n",
    "        return tf.reduce_mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "# ## 6. Load Data Splits & Compute Per-Class Weights\n",
    "\n",
    "print(\"\\nLoading data splits...\")\n",
    "\n",
    "# Split the loaded tensors into training, validation, and test sets\n",
    "train_features, temp_features, train_labels, temp_labels = train_test_split(\n",
    "    gpu_features.numpy() if tf.config.list_physical_devices('GPU') else all_features_np,\n",
    "    gpu_labels.numpy() if tf.config.list_physical_devices('GPU') else all_labels_np,\n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "val_features, test_features, val_labels, test_labels = train_test_split(\n",
    "    temp_features, temp_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Found {len(train_features)} training samples.\")\n",
    "print(f\"Found {len(val_features)} validation samples.\")\n",
    "print(f\"Found {len(test_features)} test samples.\")\n",
    "\n",
    "# Create tf.data datasets from the tensors\n",
    "BATCH_SIZE = 128 # Let's use a larger batch size now that data is in memory\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
    "train_dataset = train_dataset.shuffle(len(train_features)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_features, val_labels))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_features, test_labels))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "if not train_features.shape[0] > 0:\n",
    "    print(\"\\nError: No training data loaded. Cannot proceed with training.\")\n",
    "    exit()\n",
    "if not val_features.shape[0] > 0:\n",
    "    print(\"\\nWarning: No validation data loaded. Proceeding without validation split during training.\")\n",
    "\n",
    "# ## 7. Build & Compile the Model with Custom Loss\n",
    "INPUT_SHAPE = (N_MELS, 4, 1)\n",
    "model = build_model(INPUT_SHAPE, N_KEYS)\n",
    "\n",
    "# Create custom loss using computed per-class positive weights\n",
    "custom_loss = weighted_binary_crossentropy(class_weights)\n",
    "\n",
    "# Use LossScaleOptimizer for mixed precision training\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "            loss=custom_loss,  # Using custom weighted loss\n",
    "            # loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=[tf.keras.metrics.Precision(name='precision'),\n",
    "                     tf.keras.metrics.Recall(name='recall'),\n",
    "                     tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ## 8. Train the Model\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "# Optional: Add callbacks like EarlyStopping, ModelCheckpoint\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('/kaggle/working/best.keras', save_best_only=True, monitor='val_loss'), # Save best model\n",
    "    tf.keras.callbacks.ModelCheckpoint('/kaggle/working/final.keras', save_freq='epoch', save_best_only=False) # Save final model\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks if val_dataset else []\n",
    ")\n",
    "print(\"\\nTraining finished.\")\n",
    "\n",
    "# ## 9. Evaluate the Model (Optional)\n",
    "\n",
    "if test_dataset:\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_precision, test_recall, test_auc = model.evaluate(test_dataset)\n",
    "    print(f\"\\nTest Loss: {test_loss}\")\n",
    "    print(f\"Test Precision: {test_precision}\")\n",
    "    print(f\"Test Recall: {test_recall}\")\n",
    "    print(f\"Test AUC: {test_auc}\")\n",
    "else:\n",
    "    print(\"\\nNo test data found. Skipping final evaluation.\")\n",
    "\n",
    "# ## 10. Save the Model (Optional)\n",
    "\n",
    "# The models are already saved by the callbacks\n",
    "print(\"\\nBest model saved to /kaggle/working/best.keras\")\n",
    "print(\"Final model saved to /kaggle/working/final.keras\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 232066611,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1419.07822,
   "end_time": "2025-04-05T15:47:35.231325",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-05T15:23:56.153105",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
