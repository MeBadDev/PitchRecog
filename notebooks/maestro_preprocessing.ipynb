{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAESTRO Dataset Preprocessing\n",
    "\n",
    "This notebook preprocesses piano recordings from the MAESTRO dataset (v3.0.0) for piano note recognition model training.\n",
    "\n",
    "MAESTRO (MIDI and Audio Edited for Synchronous TRacks and Organization) dataset contains paired audio and MIDI recordings from piano performances.\n",
    "\n",
    "More info: https://magenta.tensorflow.org/datasets/maestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Requirement already satisfied: pandas in c:\\python39\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\python39\\lib\\site-packages (2.0.2)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp39-cp39-win_amd64.whl (375.7 MB)\n",
      "Requirement already satisfied: scipy in c:\\python39\\lib\\site-packages (1.13.1)\n",
      "Collecting mir_eval\n",
      "  Using cached mir_eval-0.8.2-py3-none-any.whl (102 kB)\n",
      "Collecting pretty_midi\n",
      "  Using cached pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (4.13.0)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (5.2.1)\n",
      "Collecting lazy_loader>=0.1\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\python39\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Collecting soxr>=0.3.2\n",
      "  Using cached soxr-0.5.0.post1-cp39-cp39-win_amd64.whl (167 kB)\n",
      "Collecting pooch>=1.1\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Collecting scikit-learn>=1.1.0\n",
      "  Using cached scikit_learn-1.6.1-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\python39\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Collecting joblib>=1.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\python39\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.56.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Collecting pillow>=8\n",
      "  Using cached pillow-11.1.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (24.2)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting tensorboard~=2.19.0\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.71.0-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1\n",
      "  Using cached ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl (209 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras>=3.5.0\n",
      "  Using cached keras-3.9.1-py3-none-any.whl (1.3 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.2.1-py3-none-any.whl (277 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1; python_version < \"3.12\"\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-5.29.4-cp39-cp39-win_amd64.whl (434 kB)\n",
      "Requirement already satisfied: setuptools in c:\\python39\\lib\\site-packages (from tensorflow) (49.2.1)\n",
      "Collecting h5py>=3.11.0\n",
      "  Using cached h5py-3.13.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Collecting mido>=1.1.16\n",
      "  Using cached mido-1.3.3-py3-none-any.whl (54 kB)\n",
      "Collecting cffi>=1.0\n",
      "  Using cached cffi-1.17.1-cp39-cp39-win_amd64.whl (181 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\python39\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib) (3.21.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.14.1-cp39-cp39-win_amd64.whl (291 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.6.1)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using legacy 'setup.py install' for pretty-midi, since package 'wheel' is not installed.\n",
      "Installing collected packages: pycparser, cffi, soundfile, lazy-loader, soxr, idna, urllib3, charset-normalizer, certifi, requests, pooch, threadpoolctl, joblib, scikit-learn, librosa, importlib-resources, cycler, contourpy, fonttools, pyparsing, pillow, kiwisolver, matplotlib, gast, absl-py, markdown, grpcio, protobuf, tensorboard-data-server, MarkupSafe, werkzeug, tensorboard, flatbuffers, ml-dtypes, opt-einsum, wrapt, termcolor, wheel, astunparse, google-pasta, mdurl, markdown-it-py, rich, h5py, namex, optree, keras, libclang, tensorflow-io-gcs-filesystem, tensorflow, mir-eval, mido, pretty-midi\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python39\\\\Scripts\\\\normalizer.exe' -> 'c:\\\\Python39\\\\Scripts\\\\normalizer.exe.deleteme'\n",
      "\n",
      "WARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "%pip install librosa pandas numpy matplotlib tensorflow scipy mir_eval pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python39\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4; python_version < \"3.11\" in c:\\python39\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Python39\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting librosa\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (5.2.1)\n",
      "Collecting scikit-learn>=1.1.0\n",
      "  Using cached scikit_learn-1.6.1-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\python39\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\python39\\lib\\site-packages (from librosa) (2.0.2)\n",
      "Collecting pooch>=1.1\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\python39\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Collecting joblib>=1.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (4.13.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\python39\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\python39\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python39\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\python39\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\python39\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\python39\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mebaddev\\appdata\\roaming\\python\\python39\\site-packages (from pooch>=1.1->librosa) (24.2)\n",
      "Collecting requests>=2.19.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\python39\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\python39\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn, certifi, requests, pooch, librosa\n",
      "Successfully installed certifi-2025.1.31 joblib-1.4.2 librosa-0.11.0 pooch-1.8.2 requests-2.32.3 scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpretty_midi\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\librosa\\display.py:44\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m colormaps \u001b[38;5;28;01mas\u001b[39;00m mcm\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmplaxes\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmplticker\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Install missing modules\n",
    "%pip install pandas\n",
    "%pip install librosa\n",
    "%pip install matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "import tensorflow as tf\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "RAW_DATA_PATH = \"../data/raw/maestro-v3.0.0\"\n",
    "PROCESSED_DATA_PATH = \"../data/processed/maestro-v3.0.0\"\n",
    "\n",
    "# Create processed data directory if it doesn't exist\n",
    "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Audio parameters\n",
    "SR = 22050  # Sample rate in Hz\n",
    "DURATION = 0.05  # Window size in seconds (50ms)\n",
    "HOP_LENGTH = 512  # Hop length for STFT\n",
    "N_FFT = 2048  # Number of FFT points\n",
    "N_MELS = 128  # Number of mel bands\n",
    "FMIN = 27.5  # Lowest piano key frequency (A0)\n",
    "FMAX = 4186.0  # Highest piano key frequency (C8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MAESTRO dataset metadata\n",
    "maestro_csv_path = os.path.join(RAW_DATA_PATH, \"maestro-v3.0.0.csv\")\n",
    "maestro_df = pd.read_csv(maestro_csv_path)\n",
    "maestro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data distribution\n",
    "print(f\"Total recordings: {len(maestro_df)}\")\n",
    "print(f\"Years: {maestro_df['year'].unique()}\")\n",
    "print(f\"Split distribution:\\n{maestro_df['split'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Audio Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audio_path, sr=SR):\n",
    "    \"\"\"\n",
    "    Load audio file with the specified sample rate\n",
    "    \"\"\"\n",
    "    y, _ = librosa.load(audio_path, sr=sr)\n",
    "    return y\n",
    "\n",
    "def normalize_audio(y):\n",
    "    \"\"\"\n",
    "    Amplitude normalization to range [-1, 1]\n",
    "    \"\"\"\n",
    "    return librosa.util.normalize(y)\n",
    "\n",
    "def extract_windows(y, sr=SR, duration=DURATION, hop_duration=None):\n",
    "    \"\"\"\n",
    "    Extract overlapping windows from audio\n",
    "    \"\"\"\n",
    "    window_size = int(sr * duration)\n",
    "    \n",
    "    # If hop_duration is not specified, use 50% overlap\n",
    "    if hop_duration is None:\n",
    "        hop_duration = duration / 2\n",
    "    hop_size = int(sr * hop_duration)\n",
    "    \n",
    "    # Pad the audio to ensure complete windows\n",
    "    pad_width = window_size - (len(y) % hop_size)\n",
    "    if pad_width < window_size:\n",
    "        y = np.pad(y, (0, pad_width))\n",
    "    \n",
    "    windows = []\n",
    "    timestamps = []\n",
    "    \n",
    "    # Extract windows with hop_size step\n",
    "    for start in range(0, len(y) - window_size + 1, hop_size):\n",
    "        window = y[start:start + window_size]\n",
    "        windows.append(window)\n",
    "        timestamps.append(start / sr)\n",
    "    \n",
    "    return np.array(windows), np.array(timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Compute Short-Time Fourier Transform\n",
    "    \"\"\"\n",
    "    return librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "def compute_spectrogram(stft):\n",
    "    \"\"\"\n",
    "    Compute power spectrogram from STFT\n",
    "    \"\"\"\n",
    "    return np.abs(stft) ** 2\n",
    "\n",
    "def compute_mel_spectrogram(y, sr=SR, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH, fmin=FMIN, fmax=FMAX):\n",
    "    \"\"\"\n",
    "    Compute mel spectrogram\n",
    "    \"\"\"\n",
    "    return librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_mels=n_mels, n_fft=n_fft,\n",
    "        hop_length=hop_length, fmin=fmin, fmax=fmax\n",
    "    )\n",
    "\n",
    "def compute_cqt(y, sr=SR, fmin=FMIN):\n",
    "    \"\"\"\n",
    "    Compute Constant-Q Transform\n",
    "    \"\"\"\n",
    "    return np.abs(librosa.cqt(y, sr=sr, fmin=fmin))\n",
    "\n",
    "def compute_chroma(y, sr=SR, n_chroma=12, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Compute chromagram (pitch class profile)\n",
    "    \"\"\"\n",
    "    return librosa.feature.chroma_stft(\n",
    "        y=y, sr=sr, n_chroma=n_chroma, n_fft=n_fft, hop_length=hop_length\n",
    "    )\n",
    "\n",
    "def compute_harmonic_product_spectrum(X, n_harmonics=5):\n",
    "    \"\"\"\n",
    "    Compute Harmonic Product Spectrum (HPS) to enhance fundamental frequencies\n",
    "    X: Power spectrogram\n",
    "    \"\"\"\n",
    "    H = X.copy()\n",
    "    for n in range(2, n_harmonics + 1):\n",
    "        # Downsample spectrum by factor n\n",
    "        downsampled = np.zeros_like(X)\n",
    "        for i in range(len(X) // n):\n",
    "            downsampled[i] = X[i * n]\n",
    "        H *= downsampled\n",
    "    return H\n",
    "\n",
    "def detect_onsets(y, sr=SR, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Detect note onsets\n",
    "    \"\"\"\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr, hop_length=hop_length)\n",
    "    onset_times = librosa.frames_to_time(onset_frames, sr=sr, hop_length=hop_length)\n",
    "    return onset_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MIDI Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi(midi_path):\n",
    "    \"\"\"\n",
    "    Load MIDI file\n",
    "    \"\"\"\n",
    "    return pretty_midi.PrettyMIDI(midi_path)\n",
    "\n",
    "def extract_piano_notes(midi):\n",
    "    \"\"\"\n",
    "    Extract piano notes from MIDI file with their onset/offset times\n",
    "    \"\"\"\n",
    "    notes = []\n",
    "    \n",
    "    for instrument in midi.instruments:\n",
    "        # Skip non-piano instruments if any\n",
    "        if instrument.program >= 8:  # Piano programs are 0-7 in MIDI\n",
    "            continue\n",
    "            \n",
    "        for note in instrument.notes:\n",
    "            notes.append({\n",
    "                'pitch': note.pitch,\n",
    "                'start': note.start,\n",
    "                'end': note.end,\n",
    "                'velocity': note.velocity\n",
    "            })\n",
    "    \n",
    "    return sorted(notes, key=lambda x: x['start'])\n",
    "\n",
    "def create_note_labels(notes, timestamps, duration):\n",
    "    \"\"\"\n",
    "    For each timestamp, create a binary label vector indicating\n",
    "    which notes are active during the window\n",
    "    \"\"\"\n",
    "    # 88 piano keys (21-108 MIDI pitch)\n",
    "    n_keys = 88\n",
    "    \n",
    "    # Create empty label matrix\n",
    "    labels = np.zeros((len(timestamps), n_keys))\n",
    "    \n",
    "    for i, timestamp in enumerate(timestamps):\n",
    "        # Window start and end times\n",
    "        start_time = timestamp\n",
    "        end_time = timestamp + duration\n",
    "        \n",
    "        # Find notes active during this window\n",
    "        for note in notes:\n",
    "            # Check if note overlaps with window\n",
    "            if note['end'] > start_time and note['start'] < end_time:\n",
    "                # Convert MIDI pitch to piano key index (0-87)\n",
    "                key_idx = note['pitch'] - 21\n",
    "                if 0 <= key_idx < n_keys:\n",
    "                    labels[i, key_idx] = 1\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sample(audio_path, midi_path, sample_id, output_dir, sr=SR, duration=DURATION):\n",
    "    \"\"\"\n",
    "    Preprocess a single audio-MIDI pair and save the result\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    features_dir = os.path.join(output_dir, 'features')\n",
    "    labels_dir = os.path.join(output_dir, 'labels')\n",
    "    os.makedirs(features_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "    \n",
    "    # Load and process audio\n",
    "    y = load_audio(audio_path, sr=sr)\n",
    "    y = normalize_audio(y)\n",
    "    \n",
    "    # Load and process MIDI\n",
    "    midi = load_midi(midi_path)\n",
    "    notes = extract_piano_notes(midi)\n",
    "    \n",
    "    # Extract overlapping windows and their timestamps\n",
    "    windows, timestamps = extract_windows(y, sr=sr, duration=duration)\n",
    "    \n",
    "    # Create note labels for each window\n",
    "    labels = create_note_labels(notes, timestamps, duration)\n",
    "    \n",
    "    # Store features for each window\n",
    "    all_features = []\n",
    "    \n",
    "    for i, window in enumerate(tqdm(windows, desc=f\"Processing {sample_id}\", leave=False)):\n",
    "        # Extract features\n",
    "        features = {}\n",
    "        \n",
    "        # Mel spectrogram (our primary feature)\n",
    "        mel_spec = compute_mel_spectrogram(window, sr=sr)\n",
    "        features['mel_spectrogram'] = mel_spec\n",
    "        \n",
    "        # CQT (optional)\n",
    "        # cqt = compute_cqt(window, sr=sr)\n",
    "        # features['cqt'] = cqt\n",
    "        \n",
    "        # Chroma (optional)\n",
    "        # chroma = compute_chroma(window, sr=sr)\n",
    "        # features['chroma'] = chroma\n",
    "        \n",
    "        # Save each window's features and label to separate files\n",
    "        window_id = f\"{sample_id}_{i:06d}\"\n",
    "        \n",
    "        # Save features\n",
    "        feature_path = os.path.join(features_dir, f\"{window_id}.npz\")\n",
    "        np.savez_compressed(feature_path, **features)\n",
    "        \n",
    "        # Save label\n",
    "        label_path = os.path.join(labels_dir, f\"{window_id}.npy\")\n",
    "        np.save(label_path, labels[i])\n",
    "        \n",
    "        # For demonstration, only process a subset of windows\n",
    "        if i >= 1000:  # Adjust this based on your needs\n",
    "            break\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'sample_id': sample_id,\n",
    "        'audio_path': audio_path,\n",
    "        'midi_path': midi_path,\n",
    "        'duration': len(y) / sr,\n",
    "        'n_windows': min(len(windows), 1000),  # Adjust based on limit above\n",
    "        'window_duration': duration,\n",
    "        'sr': sr\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(output_dir, f\"{sample_id}_metadata.json\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process a Subset of MAESTRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a small subset for demonstration\n",
    "# Adjust SAMPLE_COUNT or remove the limit for full dataset processing\n",
    "SAMPLE_COUNT = 5\n",
    "\n",
    "# Get a few samples from each split\n",
    "samples = {}\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    split_df = maestro_df[maestro_df['split'] == split].head(SAMPLE_COUNT)\n",
    "    samples[split] = split_df\n",
    "\n",
    "processed_metadata = []\n",
    "\n",
    "for split, split_df in samples.items():\n",
    "    # Create output directory for this split\n",
    "    split_output_dir = os.path.join(PROCESSED_DATA_PATH, split)\n",
    "    os.makedirs(split_output_dir, exist_ok=True)\n",
    "    \n",
    "    for _, row in tqdm(split_df.iterrows(), total=len(split_df), desc=f\"Processing {split} samples\"):\n",
    "        sample_id = row['canonical_composer'] + '_' + os.path.basename(row['midi_filename']).replace('.midi', '')\n",
    "        audio_path = os.path.join(RAW_DATA_PATH, row['audio_filename'])\n",
    "        midi_path = os.path.join(RAW_DATA_PATH, row['midi_filename'])\n",
    "        \n",
    "        # Skip if files don't exist\n",
    "        if not os.path.exists(audio_path) or not os.path.exists(midi_path):\n",
    "            print(f\"Skipping {sample_id} - files not found\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            metadata = preprocess_sample(audio_path, midi_path, sample_id, split_output_dir)\n",
    "            processed_metadata.append(metadata)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {sample_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample (mel spectrogram and labels)\n",
    "if processed_metadata:\n",
    "    # Get the first processed sample\n",
    "    sample_id = processed_metadata[0]['sample_id']\n",
    "    split = list(samples.keys())[0]\n",
    "    split_output_dir = os.path.join(PROCESSED_DATA_PATH, split)\n",
    "    \n",
    "    # Get the first window\n",
    "    window_id = f\"{sample_id}_000000\"\n",
    "    feature_path = os.path.join(split_output_dir, 'features', f\"{window_id}.npz\")\n",
    "    label_path = os.path.join(split_output_dir, 'labels', f\"{window_id}.npy\")\n",
    "    \n",
    "    # Load features and label\n",
    "    features = np.load(feature_path)\n",
    "    mel_spec = features['mel_spectrogram']\n",
    "    label = np.load(label_path)\n",
    "    \n",
    "    # Plot mel spectrogram\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    librosa.display.specshow(librosa.power_to_db(mel_spec, ref=np.max),\n",
    "                           y_axis='mel', x_axis='time', sr=SR, fmin=FMIN, fmax=FMAX)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Mel spectrogram - {window_id}')\n",
    "    \n",
    "    # Plot piano roll\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(label.reshape(1, -1), aspect='auto', interpolation='nearest', cmap='Blues')\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('Piano Key (A0-C8)')\n",
    "    plt.title('Active Notes')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Processed Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save overall dataset metadata\n",
    "dataset_info = {\n",
    "    'total_samples': len(processed_metadata),\n",
    "    'sample_rate': SR,\n",
    "    'window_duration': DURATION,\n",
    "    'n_mels': N_MELS,\n",
    "    'fmin': FMIN,\n",
    "    'fmax': FMAX,\n",
    "    'processed_samples': processed_metadata\n",
    "}\n",
    "\n",
    "with open(os.path.join(PROCESSED_DATA_PATH, 'dataset_info.json'), 'w') as f:\n",
    "    json.dump(dataset_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "After preprocessing, you can:\n",
    "1. Load the processed data into TensorFlow Dataset objects\n",
    "2. Build and train your model\n",
    "3. Evaluate performance on test set\n",
    "4. Optimize for latency\n",
    "\n",
    "For full dataset processing:\n",
    "- Remove the sample limit (SAMPLE_COUNT)\n",
    "- Adjust the window limit in preprocess_sample function\n",
    "- Consider using parallel processing to speed up preprocessing\n",
    "- Depending on the file size constraints, maybe use sharding or distributed processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
